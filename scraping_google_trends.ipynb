{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping-google-trends.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA1QDRsMOJB-"
      },
      "source": [
        "import codecs\n",
        "import os\n",
        "import urllib.request\n",
        "import datetime\n",
        "from xml.etree import ElementTree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijopYg0HOLDH",
        "outputId": "8b2ba92c-7192-4d04-d431-e7dc631ae91a"
      },
      "source": [
        "url = 'https://trends.google.com/trends/trendingsearches/daily/rss?geo=BR'\n",
        "#hora = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "keywords_filename = 'keywords.txt'\n",
        "tmp_filename = 'keywords_tmp.xml'\n",
        "urllib.request.urlretrieve(url, tmp_filename)\n",
        "\n",
        "if os.path.isfile(keywords_filename):\n",
        "    with open(keywords_filename, 'r') as f:\n",
        "        old_list = f.read().splitlines()\n",
        "else:\n",
        "    old_list = []\n",
        " \n",
        "tree = ElementTree.parse(tmp_filename)\n",
        "root = tree.getroot()\n",
        "fresh_list = [title.text.lower()\n",
        "              for title in root.iter('title')]\n",
        "\n",
        "#print(fresh_list)\n",
        "#fresh_list = [traffic.text.lower()\n",
        "#              for traffic in root.iter('item')]         \n",
        "#print(fresh_list)              \n",
        "\n",
        "try:\n",
        "    fresh_list.remove('daily search trends')\n",
        "except ValueError:\n",
        "    pass\n",
        "\n",
        "output = '\\n'.join(a for a in list(set(old_list + fresh_list)))\n",
        "\n",
        "with codecs.open('keywords.txt', 'w+', \"utf-8\") as f:\n",
        "    f.write(output)\n",
        "\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hbo max\n",
            "ceara\n",
            "climatempo\n",
            "sao pedro\n",
            "uruguai x paraguai\n",
            "sensação térmica\n",
            "concurso banco do brasil\n",
            "wimbledon\n",
            "temperatura\n",
            "etec\n",
            "bélgica x portugal\n",
            "espanha x croacia\n",
            "graus\n",
            "bragantino\n",
            "\t\t\t\n",
            "operário x vila nova\n",
            "vacina janssen\n",
            "vacina cuiaba\n",
            "r7\n",
            "neve em sc\n",
            "frança\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaCHCXsIOO91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}